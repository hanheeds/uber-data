#Uber Data Analytics | End-To-End Data Engineering Project (todo)

In this project, you will explore an Uber-like dataset. 

I learned how to build a data pipeline, model, and much more.

The project involves the following steps:

Data Source: Uber data set, provided in the Git repo.<br>
Ingestion Method: You’ll use Mage and Python to orchestrate and ingest the data<br>
Data Storage: The raw data will be stored in Google Cloud Storage and BigQuery<br>
Data Transformations: You’ll once again use Mage to run your transforms.<br>
Visualization: Google Looker Studio<br>
Architecture Overview: Before diving into the project details, let’s gain an understanding of the architecture that forms the foundation of our data pipeline. We will leverage Google Cloud services to store, transform, and visualize the data. The architecture diagram consists of key components like Google Cloud storage, compute engine, BigQuery, and Looker. These services work seamlessly together to ensure efficient data handling and analysis.
